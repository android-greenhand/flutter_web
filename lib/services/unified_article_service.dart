import 'package:http/http.dart' as http;
import 'dart:convert';
import 'dart:math';
import 'dart:developer' as dev;
import '../models/unified_article.dart';

/// ç»Ÿä¸€çš„æ–‡ç« æœåŠ¡ç±»ï¼Œä½¿ç”¨ UnifiedArticle æ¨¡å‹
class UnifiedArticleService {
  // ä»“åº“é…ç½®
  static const String owner = 'android-greenhand';
  static const String repo = 'Logseq';
  static const String contentsPath = 'pages/contents.md';
  // static const String contentsPath = 'logseq/bak/pages/contents/2024-06-28T09_33_18.708Z.Desktop.md';
  
  // ä¿®æ”¹ä¸º Vercel ä»£ç†æœåŠ¡åœ°å€
  static const String _baseUrl = 'https://ktor-vercel.vercel.app';

  // ç®€åŒ–çš„ headersï¼Œä¸éœ€è¦ GitHub token
  static Map<String, String> get _headers => {
    'Accept': 'application/json',
  };

  /// è·å–æ–‡ç« åˆ—è¡¨ï¼Œè¿”å› UnifiedArticle ç±»å‹
  static Future<List<UnifiedArticle>> getArticleList(String owner, String repo, String path) async {
    final url = Uri.parse('$_baseUrl/api/contents/$path?owner=$owner&repo=$repo');
    dev.log('æ­£åœ¨è¯·æ±‚æ–‡ç« åˆ—è¡¨...');
    dev.log('è¯·æ±‚ URL: ${url.toString()}');
    dev.log('è¯·æ±‚å¤´: ${_headers.toString()}');

    try {
      final response = await http.get(url, headers: _headers);
      dev.log('å“åº”çŠ¶æ€ç : ${response.statusCode}');
      if (response.statusCode == 200) {
        final List<dynamic> items = json.decode(response.body);
        dev.log('æˆåŠŸè·å–åˆ° ${items.length} ä¸ªæ–‡ä»¶');
        final articles = items
            .where((item) => item['name'].toString().endsWith('.md'))
            .map((item) {
              final name = _formatArticleName(item['name']);
              final itemPath = item['path'];
              return UnifiedArticle(
                name: name,
                title: name,
                path: itemPath,
                downloadUrl: item['download_url'],
                sha: item['sha'],
                size: item['size'],
                type: item['type'],
                description: name,
                date: DateTime.now().toIso8601String(),
                category: '',
                imageUrl: 'https://picsum.photos/800/400',
                slug: itemPath.replaceAll('.md', '').replaceAll('/', '-'),
                commitDate: DateTime.now().toIso8601String(),
              );
            })
            .toList()
          ..sort((a, b) => b.name.compareTo(a.name));
        dev.log('è¿‡æ»¤åçš„ Markdown æ–‡ç« æ•°é‡: ${articles.length}');
        return articles;
      }
      dev.log('è¯·æ±‚å¤±è´¥ï¼Œå“åº”å†…å®¹: ${response.body}', error: response.statusCode);
      throw Exception('Failed to load article list: ${response.statusCode}');
    } catch (e) {
      dev.log('è¯·æ±‚å‘ç”Ÿé”™è¯¯', error: e);
      rethrow;
    }
  }

  static String _formatArticleName(String fileName) {
    String name = fileName.replaceAll('.md', '');
    name = name.replaceAll(RegExp(r'[-_]'), ' ');
    return name.split(' ').map((word) => word.isEmpty ? '' : word[0].toUpperCase() + word.substring(1)).join(' ');
  }

  /// è·å–æ–‡ç« å†…å®¹
  static Future<String> getMarkdownContent(String owner, String repo, String path) async {
    try {
      final apiUrl = Uri.parse('$_baseUrl/api/contents/$path?owner=$owner&repo=$repo');
      print('ğŸ” [UnifiedArticleService] å¼€å§‹è·å–æ–‡ä»¶å†…å®¹');
      print('ğŸ“ [UnifiedArticleService] ä»“åº“: $owner/$repo');
      print('ğŸ“ [UnifiedArticleService] è·¯å¾„: $path');
      print('ğŸ”— [UnifiedArticleService] API URL: $apiUrl');
      final response = await http.get(apiUrl, headers: _headers);
      if (response.statusCode == 200) {
        final Map<String, dynamic> data = json.decode(response.body);
        if (!data.containsKey('content')) {
          throw Exception('å“åº”ä¸­ç¼ºå°‘æ–‡ä»¶å†…å®¹');
        }
        final rawContent = data['content'] as String;
        final cleanBase64 = rawContent.replaceAll('\n', '').replaceAll('\r', '').replaceAll(' ', '');
        try {
          final decoded = base64.decode(cleanBase64);
          final content = utf8.decode(decoded);
          final tempContent = content.replaceAllMapped(
            RegExp(r'(?<!`)`(?!`)'), // åŒ¹é…è§„åˆ™ï¼šå‰åæ— è¿ç»­åå¼•å·çš„å•ä¸ª `
                (match) => '&&',
          )
          //     .replaceAllMapped(
          //   RegExp(r'(?<!-) ```(?!\n)'), // åŒ¹é…è§„åˆ™ï¼šå‰é¢æ— å‡å·ä¸”åé¢æ— æ¢è¡Œçš„ä¸‰ä¸ªåå¼•å·
          //       (match) => '- ```',
          // ).replaceAll('```', '`')
          .replaceAll('**', '&&');
          print('tempContent $tempContent');
          return tempContent;
        } catch (e) {
          rethrow;
        }
      } else {
        throw Exception('è·å–æ–‡ä»¶å†…å®¹å¤±è´¥: ${response.statusCode}');
      }
    } catch (e) {
      throw Exception('åŠ è½½å†…å®¹é”™è¯¯: $e');
    }
  }

  static Future<String> getImageContent(String fileName) async {
    final url = Uri.parse('$_baseUrl/api/contents/$fileName?owner=$owner&repo=$repo');
    final response = await http.get(url, headers: _headers);
    if (response.statusCode == 200) {
      final Map<String, dynamic> data = json.decode(response.body);
      return data['download_url'];
    }
    throw Exception('Failed to load image: ${response.statusCode}');
  }

  static Future<Map<String, dynamic>?> getFileCommitInfo(String owner, String repo, String path) async {
    try {
      final url = Uri.parse('$_baseUrl/api/commits/$path?owner=$owner&repo=$repo');
      final response = await http.get(url, headers: _headers);
      if (response.statusCode == 200) {
        final List<dynamic> commits = json.decode(response.body);
        if (commits.isNotEmpty) {
          final commit = commits[0];
          return {
            'date': commit['commit']['author']['date'],
            'message': commit['commit']['message'],
            'author': commit['commit']['author']['name'],
          };
        }
      }
      return null;
    } catch (e) {
      dev.log('è·å–æäº¤ä¿¡æ¯å¤±è´¥', name: 'UnifiedArticleService', error: e);
      return null;
    }
  }

  // ================== åˆ†ç±»æ–‡ç« éƒ¨åˆ† ==================
  static final List<String> _skipCategories = [
    'ä¸ªäºº', 'ç”Ÿæ´»', 'æ—¥è®°', 'éšç¬”', 'ç¬¬ä¸€æ¬¡è§å®¶é•¿', 'è´·æ¬¾', 'ç›®æ ‡',
  ];

  static bool _shouldSkipCategory(String category) {
    return _skipCategories.any((skipCategory) => category.contains(skipCategory));
  }

  static Future<Map<String, List<String>>> fetchCategories() async {
    try {
      print('å¼€å§‹è·å–åˆ†ç±»ä¿¡æ¯');
      print('è¯·æ±‚è·¯å¾„: $contentsPath');
      final content = await getMarkdownContent(owner, repo, contentsPath);
      if (content.isEmpty) {
        throw Exception('è·å–åˆ†ç±»ä¿¡æ¯å¤±è´¥: å†…å®¹ä¸ºç©º');
      }
      final categories = _parseCategories(content);
      return categories;
    } catch (e, stack) {
      print('è·å–åˆ†ç±»ä¿¡æ¯å¤±è´¥');
      print('é”™è¯¯: $e');
      print('å †æ ˆ: $stack');
      rethrow;
    }
  }

  static Map<String, List<String>> _parseCategories(String markdown) {
    final Map<String, List<String>> categories = {};
    String currentCategory = '';
    int currentIndentLevel = 0;
    final lines = markdown.split('\n');
    for (var i = 0; i < lines.length; i++) {
      var line = lines[i];
      int indentLevel = line.indexOf(line.trim());
      line = line.trim();
      if (line.isEmpty) continue;
      if (line.contains('collapsed::') || line.startsWith('- **')) continue;
      if (indentLevel == 1 && line.startsWith('- [[')) {
        final match = RegExp(r'\[\[(.*?)\]\]').firstMatch(line);
        if (match != null) {
          currentCategory = match.group(1)!;
          if (_shouldSkipCategory(currentCategory)) {
            currentCategory = '';
            continue;
          }
          if (!categories.containsKey(currentCategory)) {
            categories[currentCategory] = [];
          }
          currentIndentLevel = indentLevel;
        }
      } else if (line.contains('[[') && currentCategory.isNotEmpty && indentLevel > currentIndentLevel) {
        final matches = RegExp(r'\[\[(.*?)\]\]').allMatches(line);
        for (final match in matches) {
          final title = match.group(1)!;
          if (!title.contains('http') && !title.startsWith('((') && !categories[currentCategory]!.contains(title)) {
            categories[currentCategory]!.add(title);
          }
        }
      }
    }
    return categories;
  }

  static Future<List<ArticleCategory>> getCategorizedArticles() async {
    try {
      final contents = await getMarkdownContent(owner, repo, contentsPath);
      final categoriesMap = _parseCategories(contents);
      final result = categoriesMap.entries.map((entry) {
        final categoryName = entry.key;
        final articleTitles = entry.value;
        final articles = articleTitles.map((title) {
          final path = 'pages/$title.md';
          // ç›´æ¥åˆ›å»º UnifiedArticle
          final unifiedArticle = UnifiedArticle(
            name: title,
            title: title,
            path: path,
            downloadUrl: path,
            commitDate: DateTime.now().toIso8601String(),
            imageUrl: 'https://picsum.photos/800/400',
            category: categoryName, // è®¾ç½®åˆ†ç±»
            categories: [categoryName], // åŒæ—¶è®¾ç½®categoriesæ•°ç»„
            slug: path.replaceAll('.md', '').replaceAll('/', '-'),
          );
          return unifiedArticle;
        }).toList();
        return ArticleCategory(
          name: categoryName,
          articles: articles,
        );
      }).toList();
      return result;
    } catch (e, stack) {
      print('è·å–åˆ†ç±»æ–‡ç« å¤±è´¥');
      print('é”™è¯¯: $e');
      print('å †æ ˆ: $stack');
      rethrow;
    }
  }

  /// è·å–æ‰€æœ‰åˆ†ç±»æ–‡ç« ï¼Œç›´æ¥è¿”å› UnifiedArticle åˆ—è¡¨
  static Future<List<UnifiedArticle>> getAllCategorizedArticles() async {
    try {
      final contents = await getMarkdownContent(owner, repo, contentsPath);
      final categoriesMap = _parseCategories(contents);
      
      final List<UnifiedArticle> result = [];
      
      for (final entry in categoriesMap.entries) {
        final categoryName = entry.key;
        final articleTitles = entry.value;
        
        for (final title in articleTitles) {
          final path = 'pages/$title.md';
          final unifiedArticle = UnifiedArticle(
            name: title,
            title: title,
            path: path,
            downloadUrl: path,
            commitDate: DateTime.now().toIso8601String(),
            imageUrl: 'https://picsum.photos/800/400',
            category: categoryName,
            categories: [categoryName],
            slug: path.replaceAll('.md', '').replaceAll('/', '-'),
          );
          result.add(unifiedArticle);
        }
      }
      
      return result;
    } catch (e, stack) {
      print('è·å–æ‰€æœ‰åˆ†ç±»æ–‡ç« å¤±è´¥');
      print('é”™è¯¯: $e');
      print('å †æ ˆ: $stack');
      rethrow;
    }
  }

  static Future<UnifiedArticle> getArticleDetails(UnifiedArticle article) async {
    try {
      final content = await getMarkdownContent(owner, repo, article.path);
      if (content.isEmpty) {
        return article;
      }
      final commitInfo = await getFileCommitInfo(owner, repo, article.path);
      final imageUrl = _extractImageFromContent(content);
      
      // æå–æ–‡ç« æ‘˜è¦
      final excerpt = _extractExcerpt(content);
      
      return UnifiedArticle(
        name: article.name,
        title: article.title,
        path: article.path,
        downloadUrl: article.downloadUrl,
        sha: article.sha,
        size: article.size,
        type: article.type,
        commitDate: commitInfo != null ? commitInfo['date'] ?? article.commitDate : article.commitDate,
        imageUrl: imageUrl ?? article.imageUrl,
        category: article.category,
        categories: article.categories,
        description: excerpt, // ä½¿ç”¨æ‘˜è¦ä½œä¸ºæè¿°
        excerpt: excerpt,
        content: content, // ä¿å­˜å®Œæ•´å†…å®¹
        author: commitInfo != null ? commitInfo['author'] ?? '' : '',
        date: article.date,
        slug: article.slug,
        tags: article.tags,
      );
    } catch (e) {
      print('è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥ï¼š$e');
      return article;
    }
  }

  static String? _extractImageFromContent(String content) {
    final imageRegex = RegExp(r'!\[.*?\]\((.*?)\)');
    final match = imageRegex.firstMatch(content);
    if (match != null) {
      return match.group(1);
    }
    return null;
  }
  
  static String _extractExcerpt(String content) {
    // å»é™¤ Markdown æ ‡è®°
    final plainText = content
        .replaceAll(RegExp(r'#+\s+'), '')  // ç§»é™¤æ ‡é¢˜
        .replaceAll(RegExp(r'!\[.*?\]\(.*?\)'), '')  // ç§»é™¤å›¾ç‰‡
        .replaceAll(RegExp(r'\[([^\]]*)\]\(.*?\)'), r'\$1')  // æ›¿æ¢é“¾æ¥ä¸ºæ–‡æœ¬
        .replaceAll(RegExp(r'`{1,3}.*?`{1,3}'), '')  // ç§»é™¤ä»£ç 
        .replaceAll(RegExp(r'[*_]{1,2}(.*?)[*_]{1,2}'), r'\$1')  // ç§»é™¤å¼ºè°ƒæ ‡è®°
        .trim();
    
    // è·å–å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
    final maxLength = 200;
    if (plainText.length <= maxLength) {
      return plainText;
    }
    
    return '${plainText.substring(0, maxLength)}...';
  }
} 